<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>Benjamin L Albritton</title>
 <link href="http://blalbrit.github.io/atom.xml" rel="self"/>
 <link href="http://blalbrit.github.io"/>
 <updated>2017-01-18T13:50:53-08:00</updated>
 <id>http://blalbrit.github.io</id>
 <author>
   <name>Benjamin Albritton</name>
   <email>blalbritton@gmail.com</email>
 </author>

 
 <entry>
   <title>2017-01-18 - Discussion Questions</title>
   <link href="http://blalbrit.github.io/2017/01/18/Bedford-Questions"/>
   <updated>2017-01-18T00:00:00-08:00</updated>
   <id>http://blalbrit.github.io/2017/01/18/Bedford-Questions</id>
   <content type="html">&lt;p&gt;###Discussion Questions / Thoughts
Some thoughts on the readings:
Can any online resource really be said to be “future-proof?” How can we tell what standards will survive, and which won’t?&lt;/p&gt;

&lt;p&gt;I was absolutely blown away by Deborah Parker’s project on Dante’s Inferno that Unsworth’s article mentioned, considering this was 2000. As an avid video game player, I’m always excited by projects that use visualization technology, and I was also impressed that it was backwards and forwards-compatible with other standards. I was curious if there’s been any inroads on applying VR technology to humanities studies (for example, visualizing Dante’s inferno similar to the Parker project, or even depicting how ancient cities may have looked)?&lt;/p&gt;

&lt;p&gt;Finally, some unrelated material:&lt;br /&gt;
On the collapse of standards, the &lt;a href=&quot;https://en.wikipedia.org/wiki/Year_2038_problem&quot;&gt;2038 Problem&lt;/a&gt; refers to the inability of 32-bit systems to store a time after January 17th, 2038 on their system clocks. This could potentially cause a nuclear catastrophe. Similar to my first question–how do we make things future-proof?&lt;/p&gt;

&lt;p&gt;On a less catastrophic note, check out &lt;a href=&quot;http://the-toast.net/2016/04/14/two-monks-invent-art/&quot;&gt;two monks&lt;/a&gt;, from The Toast.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>2017-01-17 - Questions 1 (May)</title>
   <link href="http://blalbrit.github.io/2017/01/17/mayquestions1"/>
   <updated>2017-01-17T00:00:00-08:00</updated>
   <id>http://blalbrit.github.io/2017/01/17/mayquestions1</id>
   <content type="html">&lt;p&gt;##Questions from Week 2 Readings&lt;/p&gt;

&lt;p&gt;The main frustration we talked about in class last week, and a theme that came up throughout the O’Donnell reading, was standardization. The narrative of his article was that, in general, online tools and editions (mostly editions) have become increasingly standardized, and these standard expectations have been a good thing. Digital editions are easier to work with, because they had to be more standardized to be usable to more viewers with the rise of the internet.&lt;/p&gt;

&lt;p&gt;But manuscript repositories are still so scattered, with apparently little consistency between them as to what information is provided about texts and objects. &lt;strong&gt;Are repositories stuck in a pre-internet age of vastly varying standards and tightly controlled usage for a specific audience?&lt;/strong&gt; And wouldn’t simplicity and adherence to strict standards allow online resources to be even more democratic (since simple sites are easier to use with poor internet access)?&lt;/p&gt;

&lt;p&gt;That leads me to my second question: in the interim between O’Donnell and Unsworth, and us today, have there been developments in crowdsourcing repositories or editions? Both seemed to value the potential of online networks of contributors, and O’Donnell praised Wikipedia’s functionality and reach. But both also seemed to see the hurdles between themselves and successfully crowdsourced tools/editions as very daunting.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Are we any closer to a repository, edition, or tool with crowd-source-ability?&lt;/strong&gt; It seems to me that this might help accomplish the immense task of providing standard information on the zillions of digitized MSS out there.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>2017-01-17 - Exercise 1 (May)</title>
   <link href="http://blalbrit.github.io/2017/01/17/maypost1"/>
   <updated>2017-01-17T00:00:00-08:00</updated>
   <id>http://blalbrit.github.io/2017/01/17/maypost1</id>
   <content type="html">&lt;p&gt;##Exercise 1&lt;/p&gt;

&lt;p&gt;For Exercise 1, I chose to critique [Digital Bodleian] (http://digital.bodleian.ox.ac.uk/) because I studied abroad in Oxford last spring and I’m feeling nostalgic, and [Gallica] (http://gallica.bnf.fr/), because I’d like to find manuscripts of Venantius Fortunatus’ poetry for a research project, and I would expect to find them in France. I’m going to just browse on the Bodleian, and then do a more targeted search on Gallica.&lt;/p&gt;

&lt;p&gt;###Digital Bodleian&lt;/p&gt;

&lt;p&gt;Digital Bodleian has a beautiful interface, and it’s immediately clear how to search for items. Before searching, though, I want to browse - below the search bar, they have several collections that seem easy to look through. When I hover over the icon of each collection, a description pops up. I’ll look at Masterpieces of the Non-Western Book.&lt;/p&gt;

&lt;p&gt;Clicking on the link took me to a different webpage, still apparently connected to the Bodleian, but in a completely different format. Looking through, if I land on a certain object in the “manuscripts” subsection, I find plenty of information about the object: shelfmark (MS. Ind. Inst. Sansk. 72), place and date of origin, incipit, size, et cetera. For each piece of information, the user can search by that information; so for instance, I can search for all other MSS with “Devanagari” in the “Script” section of the metadata.&lt;/p&gt;

&lt;p&gt;Other collections, like “Christ Church, Oxford,” link to a page within the Digital Bodleian repository and have similarly thorough information in the sidebar, without the same click-to-search option. I prefer to stay in the Digital Bodleian site over having that ease of searchability.&lt;/p&gt;

&lt;p&gt;###Gallica&lt;/p&gt;

&lt;p&gt;Gallica, the repository of the National Library of France, also has an elegant homepage. It’s too bad that the English version &lt;em&gt;n’est pas encore disponible&lt;/em&gt;. But because I know that my target author is called “Venance Fortunat” in French, I’ll search that.&lt;/p&gt;

&lt;p&gt;When I search for “Venance Fortunat,” he comes up as a “suggested author.” Two documents are associated with him, one a published and edited collection of his poetry, the other a manuscript from about the 13th century (from what I can tell). Clicking on the link to the manuscript takes me to the website of the Bibliothèque Municipal de Dijon, which does not have much more information than Gallica had - just the shelf mark and a thumbnail (which links to a high resolution scan).&lt;/p&gt;

&lt;p&gt;If I want to expand my search, I’ll try ignoring the “suggested author” and searching “Fortunat.” The immediate results are quite a few scholarly works from the last two centuries. Narrowing to manuscripts, I have a bit more luck; I’ll order them by date from early to late.&lt;/p&gt;

&lt;p&gt;Once I click on a shelf mark, the metadata disappears and I have just an image — on Digital Bodleian, I liked that the metadata stayed on a sidebar onscreen. Here, I have to go back out to my search results and click “detailed information.” I’m able to find some helpful information about dating and contents, but the size of the object, the number of pages, and really any information about the object’s materiality, is lacking.&lt;/p&gt;

&lt;p&gt;For other manuscripts, I had more luck with finding information about their physical characteristics.&lt;/p&gt;

&lt;p&gt;###General observations&lt;/p&gt;

&lt;p&gt;Digital Bodleian strikes me as the more standardized repository when it comes to providing basic necessary information about objects. After searching around in Gallica, I found that upon returning to the Bodleian I was almost relieved. I had been clicking back and forth way more than seemed necessary to find any data about objects in Gallica.&lt;/p&gt;

&lt;p&gt;I found that the more types of objects or texts the repository had, the more difficult the site was to use - especially when searching for a specific kind of object. For browsing, on the other hand, I found myself down in rabbit holes of the history of French music players and drawings of “Burmese Life and Devotion.”&lt;/p&gt;

&lt;p&gt;The flashy initial interface, and the vast array of materials in each repository, are impressive to someone stumbling around the internet for fun or perhaps seeking to answer broad historical questions. But for the targeted researcher (unless &lt;em&gt;this&lt;/em&gt; researcher is particularly incompetent), the range of dates and categories was somewhat daunting, in both cases.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>2017-01-17 - Blog Post Template</title>
   <link href="http://blalbrit.github.io/2017/01/17/templatepost"/>
   <updated>2017-01-17T00:00:00-08:00</updated>
   <id>http://blalbrit.github.io/2017/01/17/templatepost</id>
   <content type="html">&lt;h1 id=&quot;example-post&quot;&gt;Example Post&lt;/h1&gt;

&lt;p&gt;Text here.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>DLCL122-2017 - Dylan's Blog Post, Exercise 1</title>
   <link href="http://blalbrit.github.io/2017/01/17/Dylan-Blog-1"/>
   <updated>2017-01-17T00:00:00-08:00</updated>
   <id>http://blalbrit.github.io/2017/01/17/Dylan-Blog-1</id>
   <content type="html">&lt;h1 id=&quot;dylans-blog-post-1&quot;&gt;Dylan’s Blog Post #1&lt;/h1&gt;
&lt;p&gt;##Exercise 1&lt;/p&gt;

&lt;p&gt;For this exercise, I chose to look at the &lt;a href=&quot;http://cudl.lib.cam.ac.uk/&quot;&gt;Cambridge University Digital Library&lt;/a&gt;&lt;br /&gt;
as well as the The British Library’s &lt;a href=&quot;http://www.bl.uk/manuscripts/&quot;&gt;repository of manuscripts&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;###Finding the Manuscripts&lt;br /&gt;
Firstly, and perhaps most importantly: How easy is it to find each library’s collection of medieval manuscripts? I located both sites via &lt;a href=&quot;http://guides.nyu.edu/c.php?g=276597&amp;amp;p=1844931&quot;&gt;this guide&lt;/a&gt;, but what if I were approaching the websites from the libraries’ landing pages?&lt;br /&gt;
####Cambridge
The user interface for this page was very friendly, presenting the user with some simple and avanced search tools as well as categorized collections. However, this project was only started in 2010, and the library has about two millennia’s worth of content to digitize; thus, the collection is somewhat lacking.&lt;br /&gt;
The categorization system is at points too narrow, and at others too broad. One collection offers “Music,” another “Christian Works,” while yet another is solely dedicated to “notebooks kept by the soldier-poet Siegfried Sassoon.” In my opinion, they need to re-think this system. For instance, there’s no one category for medieval manuscripts. &lt;br /&gt;
Ultimately, I was able to find many in the “Christian Works” section, as well as the Royal Library, and thankfully the search tool allows you to search across categories.
Assuming one finds a manuscript one’s looking for, the image viewer is actually quite good. I was particularly impressed by the metadata accompanying the text. For the Roman de la Rose, this includes collation, binding, script, foliation, incipit and explicit, and a bibliography, among other data. It seems as though they put particular care into including metadata with the text, although this has the trade-off that adding new manuscripts to the repository might be a slow process.&lt;/p&gt;

&lt;p&gt;####British Library
The digital repository is much easier to find in this case. You can access the collection of manuscripts easily from the main page. The search is straightforward, allowing the user to input a keyword as well as define a date range (very useful if you’re only interested in a specific era) and returns results with a shelf mark and thumbnail. Unlike Cambridge, the image viewer allows you to view either one page, “open-book” style, or folio. Still, it lacks the comparison functionality of Mirador to accomodate more than one text.&lt;br /&gt;
This library also lacks the in-depth metadata that Cambridge provides. However, it also has many more texts as a whole. Perhaps these are also related; it’s difficult to add a great deal of texts and also include comprehensive data on each one. This makes it more difficult to find texts, though, since you have fewer tags with which to locate a text, and you’re searching in a bigger database.&lt;/p&gt;

&lt;p&gt;##Reflections&lt;br /&gt;
Overall, I think the two repositories take two different and valid approaches; Cambridge seems to have relatively few books, placed in easily-perusable categories, with a great deal of data on most of them. The British library has more books, but with less data and therefore more difficulty in finding specific ones. It seems to me that the Cambridge database’s use of “collections” almost make the manuscripts into museum pieces rather than texts with which you’re invited to interact, whereas the British Library is more of a useful tool that provides a great deal of content easily.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>DLCL122-2016 - Liz's Discussion Questions, Week 7</title>
   <link href="http://blalbrit.github.io/2016/02/16/lizweek7questions"/>
   <updated>2016-02-16T00:00:00-08:00</updated>
   <id>http://blalbrit.github.io/2016/02/16/lizweek7questions</id>
   <content type="html">&lt;h1 id=&quot;discussion-questions-week-7&quot;&gt;Discussion Questions, Week 7&lt;/h1&gt;

&lt;h2 id=&quot;wednesday&quot;&gt;Wednesday&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;What’s the interplay between spatial analysis and textual analysis? (the metadata analysis examples given in Tooling Up seem more like spatial analysis to me)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;How quick to adopt has medeival studeis been in comparison to other areas of the humanities when it comes to “macroanalysis”?&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>DLCL122-2016 - Christina's Discussion Questions, Week 7</title>
   <link href="http://blalbrit.github.io/2016/02/16/ChristinaWeek7DiscussionQuestions"/>
   <updated>2016-02-16T00:00:00-08:00</updated>
   <id>http://blalbrit.github.io/2016/02/16/ChristinaWeek7DiscussionQuestions</id>
   <content type="html">&lt;h1 id=&quot;week-7-discussion-questions--christina-sampling--illustrating&quot;&gt;Week 7 discussion questions–Christina (Sampling &amp;amp; Illustrating)&lt;/h1&gt;

&lt;p&gt;1.) If Voyant is an “environment,” how might one carry what is used from it into papers?  (i.e.: in order to take advantage of Voyant’s capabilites, do you really have to always be in the program itself—or what does it look like exported?)&lt;/p&gt;

&lt;p&gt;2.) Is it true that Voyant &lt;em&gt;only&lt;/em&gt; works with text? (copying and pasting text into a field–rather than Voyant being able to decipher a manuscript itself). This poses what challenges? Benefits?&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>DLCL122-2016 - Liz's Blog Post, Exercise 4</title>
   <link href="http://blalbrit.github.io/2016/02/14/lizblogpostE4"/>
   <updated>2016-02-14T00:00:00-08:00</updated>
   <id>http://blalbrit.github.io/2016/02/14/lizblogpostE4</id>
   <content type="html">&lt;p&gt;#Exercise 4: Comparing&lt;/p&gt;

&lt;p&gt;In this exercise, we were charged with the task of preparing two versions of a text for the Versioning Machine. The text I marked up was from a manuscript fragment of Rabanus Maurus’ “De rerum naturis”, which I previous transcribed in T-PEN. The second version of the text I used was an online edition which I used to assit my transcription. The turned out to be a mistake. Because I used the edition text to help expand the Latin abbreviations, and because the edition text was not at all abbreviated, the “differences” in the text were for the most part simply places where something had been abbreviated in the manuscript text. This is much less interesting than comparing two manuscript witnesses would be. So, I found the same fragment of text in a manuscript at the Parker library (CCCC MS 11) and transcribed &lt;em&gt;it&lt;/em&gt; in T-PEN, and finally adding a third witness to the TEI document for Versioning Machine.&lt;/p&gt;

&lt;h3 id=&quot;document-structure&quot;&gt;Document Structure&lt;/h3&gt;

&lt;p&gt;The fragment is from book 2, chapters 1 and 2. I used these as the top two levels of organization for the TEI encoding. Getting a breakdown smaller than that was not so clear, as there are no “paragraphs” in the Stanford manuscript. There are, however, periodic red-filled capital letters. The Stanford manuscript is the one I care about most, so I chose the red letters as a way to further decompose the text despite it seeming arbitrary from the point of view of the other two witnesses.&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;div1&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;book&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;2&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
	&lt;span class=&quot;nt&quot;&gt;&amp;lt;div2&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;chapter&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;1&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;p&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;1&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;/p&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;p&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;2&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;/p&amp;gt;&lt;/span&gt;
	&lt;span class=&quot;nt&quot;&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
	&lt;span class=&quot;nt&quot;&gt;&amp;lt;div2&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;chapter&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;2&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
	&lt;span class=&quot;nt&quot;&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;defining-difference&quot;&gt;Defining Difference&lt;/h3&gt;

&lt;p&gt;As I first did the Stanford MS and the edition text before adding the second manuscript, the only differences in the texts were abbreviation, capitialization, and punctuation differences. In order to have differences to look at, I counted all three of these things as proper differences. When I added the second manuscript witness, it produced instances like this:&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;app&amp;gt;&lt;/span&gt;
	&lt;span class=&quot;nt&quot;&gt;&amp;lt;rdg&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;wit=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;#stanfordMS&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt; filius cham[.]&lt;span class=&quot;nt&quot;&gt;&amp;lt;/rdg&amp;gt;&lt;/span&gt;
	&lt;span class=&quot;nt&quot;&gt;&amp;lt;rdg&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;wit=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;#monumenta.ch&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;, filius Cham,&lt;span class=&quot;nt&quot;&gt;&amp;lt;/rdg&amp;gt;&lt;/span&gt;
	&lt;span class=&quot;nt&quot;&gt;&amp;lt;rdg&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;wit=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;#parkerMS&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;filius cham[.]&lt;span class=&quot;nt&quot;&gt;&amp;lt;/rdg&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/app&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;To me, this seemed pretty uninteresting. The abbreviation differences in the manuscripts was the truly interesting piece. Differences in capitialization and punctuation occured fairly frequently, and were detracting from the abbreviation differences. For example:&lt;/p&gt;
&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;app&amp;gt;&lt;/span&gt;
	&lt;span class=&quot;nt&quot;&gt;&amp;lt;rdg&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;wit=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;#stanfordMS&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;iafeth dictus&lt;span class=&quot;nt&quot;&gt;&amp;lt;/rdg&amp;gt;&lt;/span&gt;
	&lt;span class=&quot;nt&quot;&gt;&amp;lt;rdg&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;wit=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;#monumenta.ch&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;Iaphet dictus&lt;span class=&quot;nt&quot;&gt;&amp;lt;/rdg&amp;gt;&lt;/span&gt;
	&lt;span class=&quot;nt&quot;&gt;&amp;lt;rdg&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;wit=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;#parkerMS&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;iapheth dict[us]&lt;span class=&quot;nt&quot;&gt;&amp;lt;/rdg&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/app&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Due to time constraints, I have not yest revised the document to reflect my new feelings on what constitutes a textual difference in this text. That’s the other thing about TEI encoding– it takes &lt;em&gt;forever&lt;/em&gt; to do and, to the computer scientist in me, looks like something which cries out for automation.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>DLCL122-2016 - Liz's Discussion Questions, Week 6</title>
   <link href="http://blalbrit.github.io/2016/02/09/lizweek6questions"/>
   <updated>2016-02-09T00:00:00-08:00</updated>
   <id>http://blalbrit.github.io/2016/02/09/lizweek6questions</id>
   <content type="html">&lt;h1 id=&quot;discussion-questions-week-6&quot;&gt;Discussion Questions, Week 6&lt;/h1&gt;

&lt;h2 id=&quot;wednesday&quot;&gt;Wednesday&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;What do we mean by “data”?&lt;/li&gt;
  &lt;li&gt;“The first Linked Data principle advocates using URI references to identify, not just Web documents and digital content, but also real world objects and abstract concepts… This principle can be seen as extending the scope of the Web from online resources to encompass any object or concept in the world.” This doesn’t seem even remotely possible as I understand it– what is going on here?&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>DLCL122-2016 - Christina's Discussion Questions, Week 6</title>
   <link href="http://blalbrit.github.io/2016/02/09/ChristinaWeek6discussionquestions"/>
   <updated>2016-02-09T00:00:00-08:00</updated>
   <id>http://blalbrit.github.io/2016/02/09/ChristinaWeek6discussionquestions</id>
   <content type="html">&lt;h1 id=&quot;week-6----discussion-questions&quot;&gt;Week 6 – Discussion questions&lt;/h1&gt;

&lt;p&gt;(1) How might we define “data”? Or, perhaps more productively, what does data not encompass?&lt;/p&gt;

&lt;p&gt;(2) In the ‘conclusions’ section of this writing on ‘Linked Data,’ the author makes mention of major companies (Google, Yahoo, Facebook) who are “busy building such data spaces.” It says here that in contrast to the open Web–accessible to everyone–these “emerging data spaces are controlled by single companies which also decide how the data spaces are exploited.”  Isn’t this a bit worrisome?  What happens when certain companies have a ‘monopoly’ on information? (This may be a broad question, but it got me thinking about the limits of this…)&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>DLCL122-2016 - Christina's Discussion Questions, Week 5</title>
   <link href="http://blalbrit.github.io/2016/02/03/csmith-week5discussion-questions"/>
   <updated>2016-02-03T00:00:00-08:00</updated>
   <id>http://blalbrit.github.io/2016/02/03/csmith-week5discussion questions</id>
   <content type="html">&lt;h1 id=&quot;week-5-discussion-questions&quot;&gt;Week 5 discussion questions&lt;/h1&gt;

&lt;p&gt;1.) Does every major institution make their image avaliable via the IIIF image API? Your (Ben Albritton’s) post mentions that more and more institutions are supporting the IIIF image API. Just out of curiosity, which ones aren’t yet? What platforms other than Mirador are utilizing this IIIF image API, allowing for comparisons across manuscripts?&lt;/p&gt;

&lt;p&gt;2.) On the “A very gentle introduction to the TEI markup language,” there’s a discussion of preservation and creating standards for “scholarly memory in an evolving digital culture.”  Since I am a ‘newbie’ to all this, is it correct that TEI is mainly used by humanities scholars?&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>DLCL122-2016 - Liz's Discussion Questions, Week 5</title>
   <link href="http://blalbrit.github.io/2016/01/31/lizdiscussionw5"/>
   <updated>2016-01-31T00:00:00-08:00</updated>
   <id>http://blalbrit.github.io/2016/01/31/lizdiscussionw5</id>
   <content type="html">&lt;h1 id=&quot;discussion-questions-week-5&quot;&gt;Discussion Questions, Week 5&lt;/h1&gt;
&lt;h2 id=&quot;monday&quot;&gt;Monday&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;What does it take for an institution to adpot IIIF? Are there economic considerations that might be slowing more adopting?&lt;/li&gt;
  &lt;li&gt;Are there different versions of the TEI DTD? Do they vary significantly?&lt;/li&gt;
  &lt;li&gt;In the examples in the Introduction to TEI, I noticed they use a link to a dtd file that doesn’t exist anymore in the doctype declaration. Advantages and disadvantages of hotlinking…&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;wednesday&quot;&gt;Wednesday&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Who generates the content of DigiPal?&lt;/li&gt;
  &lt;li&gt;How might IIIF (or a thing like it) work with tools that use polygons rather than rectangles?&lt;/li&gt;
  &lt;li&gt;i.e. is there any value in selecting a polygonal region of an image? We’ve discussed non-rectangular selection in other areas… (though of course any non-rectangular image would secretly be living inside a transparent rectangle)&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>DLCL122-2016 - Laney's Blog Post Annotations and Transcriptions</title>
   <link href="http://blalbrit.github.io/2016/01/26/laneymcg-BlogPost"/>
   <updated>2016-01-26T00:00:00-08:00</updated>
   <id>http://blalbrit.github.io/2016/01/26/laneymcg-BlogPost</id>
   <content type="html">&lt;h2 id=&quot;blog-post-annotations-and-transcriptions&quot;&gt;Blog Post Annotations and Transcriptions&lt;/h2&gt;

&lt;p&gt;For annotating and transcribing, I selected science and medicine manuscripts because the content peaked my interest.  Once I identified them for inclusion in the Mirador instance for class, I panicked, worried that selecting manuscripts for this task based upon the content might have been a bad idea. Turns out the reason for my worries was because I didn’t think I would be able to make useful annotations or be able to transcribe the text because of my inexperience.&lt;/p&gt;

&lt;h1 id=&quot;annotating&quot;&gt;Annotating&lt;/h1&gt;
&lt;p&gt;I selected a Medical treatise from the 13th century because the text has three different scripts.  I started annotating with tags indicating the script.  The manuscript is a  bi-folio with two columns per page so I wasn’t sure how to indicate which column the selected text was in.  Then I was trying to figure out if it was worth indicating which column and/or side of the bi-folio for tagging.  I did not create any annotations because I’m still not sure exactly what I am looking at in the text.  I believe once I start transcribing the text, I may have some information to add as annotation.&lt;/p&gt;

&lt;h1 id=&quot;transcribing&quot;&gt;Transcribing&lt;/h1&gt;
&lt;p&gt;I started looking at transcribing what I have indicated as script2 in the 13th century Medical treatise.  I selected this text because the font is bigger and easier to read.  However, my first attempt at transcribing was not successful.  I am finding that I still am looking at the text as I would an English language text.  It is going to take much more practice and help from others in the class to be able to complete the transcription.  Transcription is an art form and I have to remind myself that, like any new skill, it takes time to learn.  I was discouraged and my worries about not having Latin language skills surfaced along with my imposter syndrome.  But I will continue to work on improving my skills because I know I can.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>DLCL122-2016 - Christina's Blog Post, Exercise 2</title>
   <link href="http://blalbrit.github.io/2016/01/24/Christinablogpost2"/>
   <updated>2016-01-24T00:00:00-08:00</updated>
   <id>http://blalbrit.github.io/2016/01/24/Christinablogpost2</id>
   <content type="html">&lt;p&gt;Christina’s Blog post on, jointly, exercise 2 and exercise 3 (updated to reflect this)&lt;/p&gt;

&lt;p&gt;In embarking upon exercise 2—which involved utilizing Mirador to digitally annotate folia held in Stanford’s online repository—I was initially skeptical of the program’s benefits.  Indeed, it impressed me that you could store annotations for others to use, reference, or edit in future, but other than that I was unsure about the merits of Mirador.&lt;/p&gt;

&lt;p&gt;However, after using it myself to begin digitally annotating the illuminated capitals of Stanford’s c.1450 Book of Hours and Psalter (with prayers ascribed to Saint Jerome and the Venerable Bede), my mind was changed!&lt;/p&gt;

&lt;p&gt;As someone trained in rigorous visual analysis—something instilled in me by countless medieval art historians—Mirador allowed me to look at the mis-en-page and iconographic program of a codex’s folio in a new light.  For example, as I spent a fair bit of time looking at folio 13 (the first digitized folio of the MS), I was struck anew thinking about what—and how—I wanted to annotate.  Mirador’s relatively easy-to-use user interface permitted me to engage with the illuminated capitals of this folio in a way I had never done before.  Its easy ‘tag’ feature made me think about how I would characterize certain decoration, letter size, and style.  I had never before had to think about making annotations consistent and understandable to a viewer other than myself—for that is how one would interact with my annotations normally, since I wouldn’t be able to explain them in person!  Added to this is the idea that, with Mirador (like many digital technologies), my annotations remain long after I’m ‘gone.’ (Or so they should!) This gives me the responsibility and task of making sure that my annotations are consistent and can be read, understood, and reused by a myriad audience.&lt;/p&gt;

&lt;p&gt;Additionally, Mirador’s side-by-side comparative feature is wonderfully useful.  In fact, I wish every digital repository allowed one to do this! Viewing annotations for various folia within one manuscript, or across differing manuscripts, holds immense value.&lt;/p&gt;

&lt;p&gt;For me, one of the most difficult elements of trying to digitally annotate the illuminated capitals of this 1450 Book of Hours and Psalter was the fact that I didn’t know precisely how much information I should include.  At a certain point, tags (and even writing annotations within the text box) become no longer useful if there is simply &lt;em&gt;too&lt;/em&gt; much information to wade through.  In this, the ‘bold’ text feature in the text box can be used to usefully pull apart key words and terms for the casual viewer, as they engage with an illuminated initial you’ve spent much time with.  (The ‘italic’ option for text has its own problems, probably a bug—for it doesn’t allow you to make text italic and instead hides the annotation frame altogether).&lt;/p&gt;

&lt;p&gt;In all, digitally annotating using the Mirador program made me rethink how I approach study of a medieval manuscript’s visual layout—down to its most basic level.  Digitally annotating on Mirador forces the annotator to make decisions about how they will categorize what they see so that it can be (hopefully) easily searchable and usable in contexts not just within a given manuscript…but also across manuscripts.  I look forward to using the Mirador tool a LOT more, not just in our projects for this class, but in my future work as a medievalist-in-training.  In fact, I think that using Mirador would be a good exercise whenever I engage in an essay or project in which I need to closely-look (which should be almost any visually-centered endeavor).  Through the very act of having to make decisions on what you mention (or do not mention) in annotations, one is forced to engage with the text and image in a more active manner.  Using Mirador, in conjunction with viewing the &lt;em&gt;real&lt;/em&gt; manuscript (if one can), can help us as medievalists not only track and utilize our obversations later on, but also help us to question why we make certain distinctions (or not) and why these may—or may not—be important.&lt;/p&gt;

&lt;p&gt;Here, I add my thoughts on using T-PEN for online transcription. Prior to my using this program, I had done all annotations by hand. T-PEN not only (usually) sped up the process, but it also allowed me to more easily look up abbreviations on the fly.  In this, I appreciated the Latin dictionary linked to the transcription bar.  T-PEN also has excellent zoom-in features and tracking allowing you to clearly see where it is that you’re transcribing on the page (and how much you have left!).&lt;/p&gt;

&lt;p&gt;One of my favorite features of T-PEN is the comment feature, allowing you to add a note which appears below your transcription.  I appreciated that I could do this as I went along line-by-line, rather than waiting at the end.  The only thing that could have made this more user-friendly, however, would be to not only note but highlight…allowing one to more clearly point out what letterform or feature of the MS line they were commenting on.  Maybe, though, this falls more along the lines of annotation and thus is better done on Mirador.  (Ben could answer this better, though, since he knows Mirador inside out!).&lt;/p&gt;

&lt;p&gt;While these elements made T-PEN good to use, I have been struggling for a while with some bugs in the program.  For example, many &lt;em&gt;many&lt;/em&gt; times I would go back lines in my transcription (using the “previous line” feature), only to then go back to my original place (using “enter” multiple times) and find that it had grouped together lines of my text again and again.  I found this immensely frustrating!  Perhaps there is a solution to this, but I have tried to look up other users comments on T-PEN, and haven’t yet found an answer to it.  Unfortunately, this colored my appreciation of T-PEN, but I hope to figure out a way for this not to happen in the coming week(s). Overall, it speeds up the process of transcription and is quite enjoyable to use…making one feel quite productive at the end, when you see all the hard, densely-abbreviated lines you’ve ably (or not-so-ably) transcribed!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>DLCL122-2016 - Christina's Discussion Questions, Week 4</title>
   <link href="http://blalbrit.github.io/2016/01/24/week4discussionquestions"/>
   <updated>2016-01-24T00:00:00-08:00</updated>
   <id>http://blalbrit.github.io/2016/01/24/week4discussionquestions</id>
   <content type="html">&lt;p&gt;Week 4 Discussion Questions (continued from Week 3’s, which mention our other readings)–Transcription
&lt;em&gt;Note: this deals with Middle English transcriptions, not Latin. Are there slightly different things we have to consider when transcribing Latin/languages that are *not&lt;/em&gt; in English? (This also leads to the question if T-PEN is meant mostly for OE/ME and Latin; It seems to be this way considering the “Latin dictionary” tool at the bottom of the transcription window and the fact that there are shortcuts for thorn, etc.).&lt;/p&gt;

&lt;p&gt;1.) Is there a way that we can distinguish between transcribing glosses versues transcribing main text?  Perhaps this will become more clear to me as we use T-PEN in the following weeks.
2.) How much do we describe letterforms and scribal hand when we transcribe? (cf. rubrication; making mention of a particuarly interesting abbreviation/macron before we expand it; explaining the particular characteristics of a series of serifs–those “lozenge-shaped decorative finishes”)? I assume this would go into what T-PEN calls the “notes” section. The main caveat, however, that I can think of is that we wouldn’t want the notes to come up in the same window as the pure transcription–for that could distract from the main body of the text proper.  Is there a way to ‘hide’ the “notes” feature in T-PEN? (Again, this may be an obvious question, but as someone new to using T-PEN this is on my mind!).&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>DLCL122-2016 - Liz's Discussion Questions, Week 4</title>
   <link href="http://blalbrit.github.io/2016/01/24/lizdiscussion-w4"/>
   <updated>2016-01-24T00:00:00-08:00</updated>
   <id>http://blalbrit.github.io/2016/01/24/lizdiscussion-w4</id>
   <content type="html">&lt;p&gt;#Discussion Questions, Week 4
##Monday&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;How does (or should) transcription handle non-textual elements of a page (filled intertextual space or illustrations, for example)? Should it address these at all?&lt;/li&gt;
  &lt;li&gt;How do we transcribe abbreviations for which we do not know the expansion?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;##Wednesday
No questions for today.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>DLCL122-2016 - Liz's Blog Post, Exercise 2</title>
   <link href="http://blalbrit.github.io/2016/01/23/lizblog2"/>
   <updated>2016-01-23T00:00:00-08:00</updated>
   <id>http://blalbrit.github.io/2016/01/23/lizblog2</id>
   <content type="html">&lt;p&gt;#Exercise 2: Annotating&lt;/p&gt;

&lt;p&gt;Recently my interests have turned toward marginalia in manuscripts and early print books. Writing and drawing in the margins keeps books alive, show active participation in the text by humans. I am interested in who writes what, and where. Is most marginal writing part of the text, written by the scribe? Do readers tend to write more in the outer or lower margins? When readers are writing, is it more often than not related to the text they are reading?&lt;/p&gt;

&lt;p&gt;To begin exploring these questions, I browsed thorugh Stanford’s &lt;a href=&quot;https://exhibits.stanford.edu/mss/browse/browse-all&quot;&gt;digitized manuscript collection&lt;/a&gt;. Early on it became clear that legibility and my own paleographical experience would be a limiting factor, as often I found marginalia unreadable. I selected 10 items which appeared to have the most legible and interesting marginalia at a cursory glance.&lt;/p&gt;

&lt;p&gt;My original plan was to use Mirador to tag instances of marginalia (and only tag– the only written description I might want would be a transcription of the marginalia, which will come in a later exercise), based on categorizations I encountered while reading Stephen Orgel’s &lt;em&gt;The Reader in the Book&lt;/em&gt;, plus a few of my own. These categories were active reading (a reader leaving comments on a text), correction (a scribe or reader correcting the text), recording (making note of something unrelated to the text, such as a business transaction), structural (text/symbols that are part of the structure of the text, such as section numbering), and illustration (doodles, maniculae, etc).&lt;/p&gt;

&lt;p&gt;Satisfied with the coverage of my categories, I set off to tag. Right away I found it quite difficult to fit what I was seeing on the page into the categories, not because the categories were insufficient but because, as previously feared, my ability to read the text was limiting progress. While I had done well to choose the most legible examples I could find in the collection, making out characters was still a challenge, and my minimal knowledge of Latin was doing me no favors. Structural elements and illustration were easy to pick out, but corrections, recordings, and active reading I found near indistinguishable. Without writing out a full transcription of everything I found, I was getting nowhere fast. Since transcription is to be done in the coming weeks, I changed my strategy. Rather than tagging based on my original categories, I tagged (and re-tagged) based on whether the marginalia appeared to be scribal or non-scribal. This, too, was not as easy as it might be for someone with more paleographic experience; I am satisfied that what I have is &lt;em&gt;close enough&lt;/em&gt; for this initial step.&lt;/p&gt;

&lt;p&gt;The outcome of this exerise is not quite what I desired before starting, but I have been able to make a couple of observations so far. First, that most of the marginal writing in these items appears to be non-scribal. This is in line with what I would have predicted– I would assume that more often than not if a scribe had something to say or correct, it would be in the body of the text. Second, what I did not expect to see (or did not think to expect) is that scribal writing appears more frequenty in the left and right margins, and is less likely to be written in a way that is not in line with the appearance of the page (upside down, or sideways, for example). After transcription I hope to be able to explore the reasons behind these observations, and inch closer to my original categorization scheme.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>DLCL122-2016 - Christina's Discussion Questions, Week 3</title>
   <link href="http://blalbrit.github.io/2016/01/20/week3discussionquestions"/>
   <updated>2016-01-20T00:00:00-08:00</updated>
   <id>http://blalbrit.github.io/2016/01/20/week3discussionquestions</id>
   <content type="html">&lt;h1 id=&quot;week-3-discussion-questions&quot;&gt;Week 3 discussion questions&lt;/h1&gt;

&lt;p&gt;1) Clemens and Graham’s chapter on correction, glossing, and annotation talks about the scribal tools and techniques involved in the “nitty-gritty” elements of manuscript production. As someone new to digital renditions of manuscripts (having transcribed them solely by hand in the past) how do digital humanists usually account for erasures and re-writing over those marked-out areas?  If we believe a medieval scribe to have made the error of “eyeskip” (which C&amp;amp;G define as omitting the same word, phrase, or sequence of letters that appear twice in close succession) how can we make note of this in our digital annotation?&lt;br /&gt;
—-And now a question of glossing: do we treat the location of where certain glosses are (cf. glossae collectae–those fully separate from the text itself; interlinear glosses; glosses in the main text) and what type they are (lexical/synonym vs. suppletive/omissions) &lt;em&gt;differently&lt;/em&gt; when we go into annotating them digitally?&lt;/p&gt;

&lt;p&gt;2) Digital Mappaemundi (Maps of the World) disusses the use of digital ‘layers,’ whereby “different research questions involving a single image may be addressed separately through annotation (also allowing one to choose precisely how &lt;em&gt;many&lt;/em&gt; layers they would like to view at one time). This seems to present a solution to our frustration with the BL’s excess of metadata in lengthy, sometimes-bordering-upon-impenetrable, paragraphs. How common are digital layers in literary manuscripts?  As its name suggests, the Mappaemundi project focuses on maps mostly.
—-Think more about: Geospatial bias and how it can relate to literary/biblical/philosophical texts too? (cf. C&amp;amp;G’s term “archaeology of the book” and idea of the book as a space)&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>DLCL122-2016 - Liz's Discussion Questions, Week 3</title>
   <link href="http://blalbrit.github.io/2016/01/20/liz-discussion-w3"/>
   <updated>2016-01-20T00:00:00-08:00</updated>
   <id>http://blalbrit.github.io/2016/01/20/liz-discussion-w3</id>
   <content type="html">&lt;p&gt;#Discussion Questions, Week 3
##Monday
No class.&lt;/p&gt;

&lt;p&gt;##Wednesday&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;In the reading on Digital Mappaemundi the authors mentioned features of plans for features that addressed each of the scholarly primitives we have discussed previously. I’ve noticed a trend, between the Mirador Github issues, this reading, and technology generally  toward expecting one platform/application to address all our needs– is this desirable?&lt;/li&gt;
  &lt;li&gt;Is it defeatist to say there are problems that aren’t worth trying to solve, at least until there is a complete overhaul of the current approach? When is it okay to give up on a project?&lt;/li&gt;
  &lt;li&gt;What can physical annotation do that the tools we’ve seen so far does not replicate sufficiently? Are these tools still working to replace physical annotation, or strictly building on it?&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>DLCL122-2016 - Christina's Discussion Questions, Week 2, part 2</title>
   <link href="http://blalbrit.github.io/2016/01/13/week2discussionquestions"/>
   <updated>2016-01-13T00:00:00-08:00</updated>
   <id>http://blalbrit.github.io/2016/01/13/week2discussionquestions</id>
   <content type="html">&lt;h1 id=&quot;week-2-discussion-questions-christina&quot;&gt;Week 2 discussion questions (Christina)&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;In the words of Hilmo, “Medieval reading often included looking, in a non-linear, holistic way, at all the components of the page.”  The overall theme of Hilmo’s essay is on the centrality of the visual—images—in the medieval mind.  Hilmo speaks of how images can, and should, be read as text (cf. the monastic practice of ruminatio, per Bede’s 8th-c. account of Caedmon), as something which requires unpacking and a peeling-back of layers.  How might this relate to our discussion of the tasks involved in annotation and transcription?
    &lt;ul&gt;
      &lt;li&gt;Moreover: To the medieval mind an image was an animative, performative presence to be decoded and ruminated upon (particularly with the rise of mendicant orders).  This usually involved having a ‘toolkit’ of symbolism and connections at the ready. How might we, as modern viewers, recreate this ‘toolkit’ of connections through our digital presenting of manuscripts?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Do we need to take into account the basic genre of a manuscript (sacred, secular, somewhere-in-between) when creating a digital tool for studying it?  In other words, Hilmo’s essay deals with manuscripts containing visual images–something usually restricted to the domain of art historians.  How might the technologies we produce for medieval objects (the codex, in particular) tread the line between being produced for scholars of text versus scholars of image? (The text v. image comparison is one made frequently in medieval studies–whereby text becomes image, and image becomes text).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;An aside: Has there been a digital survey of iconophobic evidence in western manuscripts (British, Carolingian…and Byzantine, if we head into eastern MSs)?  Ie: smudgings out of eyes, etc.  I began to think along these terms because a) it’s the topic of my thesis and b) Hilmo’s essay begins with, essentially, a brief survey of western (and some eastern–Byzantium, Islamic) concern over the ‘power’ invested in images.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 
</feed>
